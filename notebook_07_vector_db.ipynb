{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building LLM applications: Notebook 07\n",
    "\n",
    "# Vector DBs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'llama3.2:3b-instruct-fp16'\n",
    "EMBEDING_MODEL = 'nomic-embed-text'\n",
    "\n",
    "DATA_DIR = Path('.') / 'data'\n",
    "CHROMA_PATH = DATA_DIR / 'chroma'\n",
    "DOCS_DIR = DATA_DIR / 'books'\n",
    "\n",
    "CHROMA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "_db_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Ollama server: local\n"
     ]
    }
   ],
   "source": [
    "# Read fro `.env` file\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "OLLAMA_URL = os.getenv('OLLAMA_URL')\n",
    "print(f\"Using Ollama server: {OLLAMA_URL if OLLAMA_URL else 'local'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OllamaEmbeddings(model=EMBEDING_MODEL, base_url=OLLAMA_URL)\n",
    "vdb = Chroma(persist_directory=str(CHROMA_PATH), embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_ids(force=False):\n",
    "    \"\"\" Get the ids of the documents in the database \"\"\"\n",
    "    global _db_ids\n",
    "    if _db_ids is None or force:\n",
    "        items = vdb.get(include=[])\n",
    "        _db_ids = set(items['ids'])\n",
    "    return _db_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_paragraph_to_vdb(file: Path, paragraph_num: int, paragraph: str):\n",
    "    \"\"\"\n",
    "    Add a paragraph to the database \n",
    "    Returns 1 if the paragraph was added, 0 otherwise\n",
    "    \"\"\"\n",
    "    # Ignore empty or short paragraphs\n",
    "    if not paragraph.strip() or len(paragraph.strip().split('\\n')) < 3:\n",
    "        return 0\n",
    "    # Skipt already added ids\n",
    "    doc_id = f\"{file.stem}-{paragraph_num}\"\n",
    "    if doc_id in get_db_ids():\n",
    "        return 0\n",
    "    # Add to database\n",
    "    metadata = {'source': str(file.stem), 'paragraph': paragraph_num}\n",
    "    doc = Document(page_content=paragraph, metadata=metadata)\n",
    "    vdb.add_documents([doc], ids=[doc_id])\n",
    "    # print(f\"Added document {doc_id}\")\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_book_to_db(file: Path):\n",
    "    \"\"\"\n",
    "    Add a book to the database \n",
    "    Returns the number of paragraphs added\n",
    "    \"\"\"\n",
    "    text = file.read_text()\n",
    "    # Split by paragraphs (empty lines)\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "    print(f\"\\nReading file '{file}, found {len(paragraphs)} paragraphs\")\n",
    "    count_added = 0\n",
    "    for i, p in enumerate(paragraphs):\n",
    "        count_added += add_paragraph_to_vdb(file, i, p)\n",
    "        if i % 100 == 0:\n",
    "            print(f\"\\n{i}\\t:\", end='', flush=True)\n",
    "        print('.', end='', flush=True)\n",
    "    return count_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading file 'data/books/dracula_chapter_1.txt, found 44 paragraphs\n",
      "\n",
      "0\t:............................................\n",
      "Reading file 'data/books/hhgttg_chunk_1.txt, found 380 paragraphs\n",
      "\n",
      "0\t:....................................................................................................\n",
      "100\t:....................................................................................................\n",
      "200\t:....................................................................................................\n",
      "300\t:................................................................................"
     ]
    }
   ],
   "source": [
    "# Add all books to the database\n",
    "for txt_file in DOCS_DIR.glob('*.txt'):\n",
    "    add_book_to_db(txt_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
