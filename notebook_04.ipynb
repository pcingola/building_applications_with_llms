{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building LLM applications: Notebook 04\n",
    "\n",
    "# ReAct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import json\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnablePassthrough\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langchain.agents.output_parsers.react_single_input import ReActSingleInputOutputParser\n",
    "\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Ollama server: local\n"
     ]
    }
   ],
   "source": [
    "# Read fro `.env` file\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "OLLAMA_URL = os.getenv('OLLAMA_URL')\n",
    "print(f\"Using Ollama server: {OLLAMA_URL if OLLAMA_URL else 'local'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReAct Agent\n",
    "\n",
    "**WARNING**: We are using an \"old fasion\" implementation based on `AgentExecutor` for illustration pourposes only.\n",
    "A more \"modern\" approach is to use LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create tools (`str` parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def double_of(n):\n",
    "    \"\"\"Double of a number\"\"\"\n",
    "    print(f\"Double of (type: {type(n)}) {n}\")\n",
    "    n = int(n)\n",
    "    print(f\"Double of {n}\")\n",
    "    return 2 * n\n",
    "\n",
    "\n",
    "@tool\n",
    "def factorial_of(n):\n",
    "    \"\"\"Factorial of a number\"\"\"\n",
    "    print(f\"Factorial of (type: {type(n)}) {n}\")\n",
    "    n = int(n)\n",
    "    fact = 1\n",
    "    for i in range(1, n+1):\n",
    "        fact *= i\n",
    "    return fact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'double_of': StructuredTool(name='double_of', description='Double of a number', args_schema=<class 'langchain_core.utils.pydantic.double_of'>, func=<function double_of at 0x1180f0220>),\n",
       " 'factorial_of': StructuredTool(name='factorial_of', description='Factorial of a number', args_schema=<class 'langchain_core.utils.pydantic.factorial_of'>, func=<function factorial_of at 0x10fc6fe20>)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [double_of, factorial_of]\n",
    "tools_map = {t.name.lower(): t for t in tools}\n",
    "tools_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a ReAct Agent prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names'], input_types={}, partial_variables={}, template='Use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}\\n')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "\n",
    "\n",
    "# Create the LLM object\n",
    "llm = ChatOllama(model=MODEL, base_url=OLLAMA_URL)\n",
    "\n",
    "# Create a prompt object from the string template\n",
    "prompt_template = \"\"\"Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: We need to add the `intermediate_steps` to the `agent_scratchpad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.agents import AgentAction\n",
    "\n",
    "def format_log_to_str(\n",
    "    intermediate_steps: list[tuple[AgentAction, str]],\n",
    "    observation_prefix: str = \"Observation: \",\n",
    "    llm_prefix: str = \"Thought: \",\n",
    ") -> str:\n",
    "    \"\"\"Construct the scratchpad that lets the agent continue its thought process.\"\"\"\n",
    "    thoughts = \"\"\n",
    "    for action, observation in intermediate_steps:\n",
    "        thoughts += action.log\n",
    "        thoughts += f\"\\n{observation_prefix}{observation}\\n{llm_prefix}\"\n",
    "    return thoughts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create the `AgentExecutor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# agent_debug = DebugRunnable('Before agent') | agent | DebugRunnable('After agent')\n",
    "\n",
    "llm_with_stop = llm.bind(stop=[\"\\nObservation\"])\n",
    "agent = (\n",
    "    RunnablePassthrough.assign(\n",
    "        agent_scratchpad=lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n",
    "    )\n",
    "    | prompt\n",
    "    | llm_with_stop\n",
    "    | ReActSingleInputOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorial of (type: <class 'str'>) 10\n",
      "Double of (type: <class 'str'>) 3628800\n",
      "Double of 3628800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the factorial of 10?',\n",
       " 'tool_names': 'double_of,factorial_of',\n",
       " 'output': '7257600'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the factorial of 10?\"\n",
    "tool_names = ','.join([t.name for t in tools])\n",
    "\n",
    "agent_executor.invoke({'input': query, 'tool_names': tool_names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
